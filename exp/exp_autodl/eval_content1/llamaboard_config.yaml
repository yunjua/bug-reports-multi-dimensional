eval.batch_size: 2
eval.cutoff_len: 1024
eval.dataset:
- exp_test_modified
eval.dataset_dir: data
eval.max_new_tokens: 512
eval.max_samples: '750'
eval.output_dir: eval_content1
eval.predict: true
eval.temperature: 0.5
eval.top_p: 0.7
top.booster: none
top.checkpoint_path:
- train_exp
top.finetuning_type: lora
top.model_name: LLaMA3-8B
top.quantization_bit: none
top.rope_scaling: none
top.template: llama3
top.visual_inputs: false
